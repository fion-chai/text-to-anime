{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-to-anime.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clGEXgmnkX4K",
        "outputId": "d909aab9-2046-438e-b2b3-e57d6fa0e2b9"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/PhD/CE7455 - NLP/Project/text-to-anime\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PhD/CE7455 - NLP/Project/text-to-anime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWYMKzjoo-R6",
        "outputId": "6ef887fa-6a4f-4c2c-abe0-5076e9606e94"
      },
      "source": [
        "%pip install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.10.0+cu111)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.1.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python->-r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 4)) (3.10.0.2)\n",
            "Installing collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvdskGbPpE5Q",
        "outputId": "6ab4ae43-69ab-4cff-ded1-4543111f3e83"
      },
      "source": [
        "import torch\n",
        "\n",
        "from train import main\n",
        "from utils import HParams\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "hparams = HParams(\n",
        "    n_landmark_xyz=60,\n",
        "    # max_decoder_steps=240,\n",
        "    epochs=50,\n",
        "    iters_per_checkpoint=45,\n",
        "    learning_rate=2e-3,\n",
        "    batch_size=8,\n",
        "    fp16_run=True,\n",
        "    pretrain=False,\n",
        ")\n",
        "main(hparams)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Train loss 1 0.485146 Grad Norm 0.104303 8.36s/it\n",
            "Train loss 2 0.439064 Grad Norm 0.089095 13.84s/it\n",
            "Train loss 3 0.189383 Grad Norm 0.075866 24.95s/it\n",
            "Train loss 4 0.418490 Grad Norm 0.107349 8.52s/it\n",
            "Train loss 5 0.235338 Grad Norm 0.066065 17.48s/it\n",
            "Train loss 6 0.411732 Grad Norm 0.094662 19.94s/it\n",
            "Train loss 7 0.280149 Grad Norm 0.092825 19.96s/it\n",
            "Train loss 8 0.243173 Grad Norm 0.070561 32.82s/it\n",
            "Train loss 9 0.257296 Grad Norm 0.074152 22.56s/it\n",
            "Epoch: 1\n",
            "Train loss 10 0.198204 Grad Norm 0.062897 33.81s/it\n",
            "Train loss 11 0.250955 Grad Norm 0.080470 29.80s/it\n",
            "Train loss 12 0.387731 Grad Norm 0.127375 17.08s/it\n",
            "Train loss 13 0.243176 Grad Norm 0.101785 25.15s/it\n",
            "Train loss 14 0.327691 Grad Norm 0.123296 11.63s/it\n",
            "Train loss 15 0.240962 Grad Norm 0.107890 20.19s/it\n",
            "Train loss 16 0.109004 Grad Norm 0.077607 25.14s/it\n",
            "Train loss 17 0.207911 Grad Norm 0.107134 12.50s/it\n",
            "Train loss 18 0.128434 Grad Norm 0.089984 21.34s/it\n",
            "Epoch: 2\n",
            "Train loss 19 0.201045 Grad Norm 0.103669 18.79s/it\n",
            "Train loss 20 0.137392 Grad Norm 0.110780 25.14s/it\n",
            "Train loss 21 0.097702 Grad Norm 0.084776 29.28s/it\n",
            "Train loss 22 0.100238 Grad Norm 0.100764 21.65s/it\n",
            "Train loss 23 0.177451 Grad Norm 0.109297 20.23s/it\n",
            "Train loss 24 0.215763 Grad Norm 0.141966 12.90s/it\n",
            "Train loss 25 0.169637 Grad Norm 0.120022 22.73s/it\n",
            "Train loss 26 0.099839 Grad Norm 0.092439 24.76s/it\n",
            "Train loss 27 0.267650 Grad Norm 0.152748 13.42s/it\n",
            "Epoch: 3\n",
            "Train loss 28 0.144330 Grad Norm 0.091330 21.10s/it\n",
            "Train loss 29 0.096722 Grad Norm 0.069438 21.62s/it\n",
            "Train loss 30 0.186061 Grad Norm 0.115303 8.42s/it\n",
            "Train loss 31 0.156692 Grad Norm 0.104718 7.92s/it\n",
            "Train loss 32 0.188512 Grad Norm 0.141333 17.22s/it\n",
            "Train loss 33 0.110905 Grad Norm 0.090119 17.41s/it\n",
            "Train loss 34 0.119255 Grad Norm 0.103893 25.22s/it\n",
            "Train loss 35 0.065903 Grad Norm 0.087076 24.90s/it\n",
            "Train loss 36 0.076967 Grad Norm 0.098258 32.85s/it\n",
            "Epoch: 4\n",
            "Train loss 37 0.089609 Grad Norm 0.097419 21.49s/it\n",
            "Train loss 38 0.135824 Grad Norm 0.149954 7.30s/it\n",
            "Train loss 39 0.102346 Grad Norm 0.106556 13.69s/it\n",
            "Train loss 40 0.082425 Grad Norm 0.076948 22.62s/it\n",
            "Train loss 41 0.090509 Grad Norm 0.113126 17.83s/it\n",
            "Train loss 42 0.101333 Grad Norm 0.194710 10.18s/it\n",
            "Train loss 43 0.069120 Grad Norm 0.130441 29.33s/it\n",
            "Train loss 44 0.046340 Grad Norm 0.068285 32.80s/it\n",
            "Train loss 45 0.055097 Grad Norm 0.092600 19.96s/it\n",
            "Validation loss 45:  0.111008\n",
            "Saving model and optimizer state at iteration 45 to best.pt\n",
            "Epoch: 5\n",
            "Train loss 46 0.101676 Grad Norm 0.176695 15.07s/it\n",
            "Train loss 47 0.054151 Grad Norm 0.105224 18.00s/it\n",
            "Train loss 48 0.099608 Grad Norm 0.142349 8.29s/it\n",
            "Train loss 49 0.043072 Grad Norm 0.079824 29.30s/it\n",
            "Train loss 50 0.103944 Grad Norm 0.235517 7.40s/it\n",
            "Train loss 51 0.042862 Grad Norm 0.148857 20.43s/it\n",
            "Train loss 52 0.039155 Grad Norm 0.085769 25.31s/it\n",
            "Train loss 53 0.024641 Grad Norm 0.061790 32.78s/it\n",
            "Train loss 54 0.051038 Grad Norm 0.106226 25.00s/it\n",
            "Epoch: 6\n",
            "Train loss 55 0.038572 Grad Norm 0.082726 23.72s/it\n",
            "Train loss 56 0.028842 Grad Norm 0.045611 24.98s/it\n",
            "Train loss 57 0.058167 Grad Norm 0.136006 20.43s/it\n",
            "Train loss 58 0.037814 Grad Norm 0.111149 20.29s/it\n",
            "Train loss 59 0.062409 Grad Norm 0.157074 10.00s/it\n",
            "Train loss 60 0.034756 Grad Norm 0.079165 17.81s/it\n",
            "Train loss 61 0.025724 Grad Norm 0.075496 25.14s/it\n",
            "Train loss 62 0.043423 Grad Norm 0.114478 32.86s/it\n",
            "Train loss 63 0.033791 Grad Norm 0.091304 21.47s/it\n",
            "Epoch: 7\n",
            "Train loss 64 0.041903 Grad Norm 0.098298 11.26s/it\n",
            "Train loss 65 0.038517 Grad Norm 0.077521 20.41s/it\n",
            "Train loss 66 0.025070 Grad Norm 0.065590 29.52s/it\n",
            "Train loss 67 0.023464 Grad Norm 0.051984 21.69s/it\n",
            "Train loss 68 0.031843 Grad Norm 0.069314 17.78s/it\n",
            "Train loss 69 0.030178 Grad Norm 0.078407 20.33s/it\n",
            "Train loss 70 0.041223 Grad Norm 0.134178 12.92s/it\n",
            "Train loss 71 0.025947 Grad Norm 0.058930 32.77s/it\n",
            "Train loss 72 0.037740 Grad Norm 0.123507 24.81s/it\n",
            "Epoch: 8\n",
            "Train loss 73 0.020951 Grad Norm 0.059296 34.11s/it\n",
            "Train loss 74 0.025839 Grad Norm 0.081586 29.37s/it\n",
            "Train loss 75 0.029677 Grad Norm 0.061488 11.18s/it\n",
            "Train loss 76 0.057634 Grad Norm 0.125268 8.53s/it\n",
            "Train loss 77 0.028729 Grad Norm 0.097068 25.11s/it\n",
            "Train loss 78 0.038559 Grad Norm 0.118456 13.74s/it\n",
            "Train loss 79 0.027602 Grad Norm 0.096149 24.79s/it\n",
            "Train loss 80 0.040729 Grad Norm 0.150098 19.82s/it\n",
            "Train loss 81 0.026889 Grad Norm 0.067063 12.52s/it\n",
            "Epoch: 9\n",
            "Train loss 82 0.023395 Grad Norm 0.075342 33.77s/it\n",
            "Train loss 83 0.031219 Grad Norm 0.077273 21.68s/it\n",
            "Train loss 84 0.041635 Grad Norm 0.106874 13.71s/it\n",
            "Train loss 85 0.040095 Grad Norm 0.110652 10.16s/it\n",
            "Train loss 86 0.049869 Grad Norm 0.171117 7.19s/it\n",
            "Train loss 87 0.037927 Grad Norm 0.099529 29.31s/it\n",
            "Train loss 88 0.025351 Grad Norm 0.074594 24.97s/it\n",
            "Train loss 89 0.050020 Grad Norm 0.122401 10.80s/it\n",
            "Train loss 90 0.021925 Grad Norm 0.045556 24.89s/it\n",
            "Validation loss 90:  0.060941\n",
            "Saving model and optimizer state at iteration 90 to best.pt\n",
            "Epoch: 10\n",
            "Train loss 91 0.029838 Grad Norm 0.063641 32.09s/it\n",
            "Train loss 92 0.079463 Grad Norm 0.180052 7.39s/it\n",
            "Train loss 93 0.032820 Grad Norm 0.077737 25.10s/it\n",
            "Train loss 94 0.057007 Grad Norm 0.163450 12.86s/it\n",
            "Train loss 95 0.042323 Grad Norm 0.128123 17.62s/it\n",
            "Train loss 96 0.021554 Grad Norm 0.053085 32.90s/it\n",
            "Train loss 97 0.020899 Grad Norm 0.061062 20.27s/it\n",
            "Train loss 98 0.024063 Grad Norm 0.056997 21.43s/it\n",
            "Train loss 99 0.040660 Grad Norm 0.107932 19.82s/it\n",
            "Epoch: 11\n",
            "Train loss 100 0.033712 Grad Norm 0.071374 13.55s/it\n",
            "Train loss 101 0.029256 Grad Norm 0.071813 11.35s/it\n",
            "Train loss 102 0.042510 Grad Norm 0.116221 20.16s/it\n",
            "Train loss 103 0.026427 Grad Norm 0.058977 7.37s/it\n",
            "Train loss 104 0.031721 Grad Norm 0.075365 24.99s/it\n",
            "Train loss 105 0.025166 Grad Norm 0.086229 23.19s/it\n",
            "Train loss 106 0.026614 Grad Norm 0.067247 29.59s/it\n",
            "Train loss 107 0.024200 Grad Norm 0.064892 24.85s/it\n",
            "Train loss 108 0.018741 Grad Norm 0.042254 32.83s/it\n",
            "Epoch: 12\n",
            "Train loss 109 0.021057 Grad Norm 0.049466 21.15s/it\n",
            "Train loss 110 0.017666 Grad Norm 0.041386 21.59s/it\n",
            "Train loss 111 0.031494 Grad Norm 0.076749 8.71s/it\n",
            "Train loss 112 0.017598 Grad Norm 0.040162 17.93s/it\n",
            "Train loss 113 0.014499 Grad Norm 0.033612 29.45s/it\n",
            "Train loss 114 0.035767 Grad Norm 0.129160 17.57s/it\n",
            "Train loss 115 0.016983 Grad Norm 0.048186 20.44s/it\n",
            "Train loss 116 0.030362 Grad Norm 0.108349 24.77s/it\n",
            "Train loss 117 0.023961 Grad Norm 0.121305 32.83s/it\n",
            "Epoch: 13\n",
            "Train loss 118 0.042950 Grad Norm 0.222276 11.40s/it\n",
            "Train loss 119 0.027181 Grad Norm 0.076575 25.05s/it\n",
            "Train loss 120 0.040248 Grad Norm 0.109350 11.47s/it\n",
            "Train loss 121 0.028414 Grad Norm 0.068792 20.34s/it\n",
            "Train loss 122 0.025820 Grad Norm 0.077422 11.02s/it\n",
            "Train loss 123 0.016970 Grad Norm 0.041739 32.90s/it\n",
            "Train loss 124 0.028887 Grad Norm 0.101789 29.55s/it\n",
            "Train loss 125 0.016076 Grad Norm 0.038475 21.45s/it\n",
            "Train loss 126 0.019269 Grad Norm 0.055897 24.96s/it\n",
            "Epoch: 14\n",
            "Train loss 127 0.040812 Grad Norm 0.160733 20.84s/it\n",
            "Train loss 128 0.022440 Grad Norm 0.060420 25.03s/it\n",
            "Train loss 129 0.017876 Grad Norm 0.053107 32.96s/it\n",
            "Train loss 130 0.041350 Grad Norm 0.096816 29.29s/it\n",
            "Train loss 131 0.037039 Grad Norm 0.090354 17.13s/it\n",
            "Train loss 132 0.014693 Grad Norm 0.033617 24.96s/it\n",
            "Train loss 133 0.020452 Grad Norm 0.059480 22.79s/it\n",
            "Train loss 134 0.034512 Grad Norm 0.070504 8.04s/it\n",
            "Train loss 135 0.024774 Grad Norm 0.052615 21.38s/it\n",
            "Validation loss 135:  0.041189\n",
            "Saving model and optimizer state at iteration 135 to best.pt\n",
            "Epoch: 15\n",
            "Train loss 136 0.027647 Grad Norm 0.062506 15.06s/it\n",
            "Train loss 137 0.038316 Grad Norm 0.081590 11.20s/it\n",
            "Train loss 138 0.026949 Grad Norm 0.085125 25.27s/it\n",
            "Train loss 139 0.013122 Grad Norm 0.035195 17.82s/it\n",
            "Train loss 140 0.018561 Grad Norm 0.061130 33.12s/it\n",
            "Train loss 141 0.038017 Grad Norm 0.089587 12.07s/it\n",
            "Train loss 142 0.015204 Grad Norm 0.048641 17.36s/it\n",
            "Train loss 143 0.016943 Grad Norm 0.049901 22.58s/it\n",
            "Train loss 144 0.016366 Grad Norm 0.043800 19.98s/it\n",
            "Epoch: 16\n",
            "Train loss 145 0.028518 Grad Norm 0.071924 11.67s/it\n",
            "Train loss 146 0.016870 Grad Norm 0.034482 16.83s/it\n",
            "Train loss 147 0.015173 Grad Norm 0.047906 24.90s/it\n",
            "Train loss 148 0.028216 Grad Norm 0.086687 10.65s/it\n",
            "Train loss 149 0.022434 Grad Norm 0.131120 25.29s/it\n",
            "Train loss 150 0.009955 Grad Norm 0.033487 33.10s/it\n",
            "Train loss 151 0.036444 Grad Norm 0.131347 22.94s/it\n",
            "Train loss 152 0.013497 Grad Norm 0.036911 29.24s/it\n",
            "Train loss 153 0.015934 Grad Norm 0.053477 21.48s/it\n",
            "Epoch: 17\n",
            "Train loss 154 0.037822 Grad Norm 0.154861 20.90s/it\n",
            "Train loss 155 0.014366 Grad Norm 0.040598 20.29s/it\n",
            "Train loss 156 0.024867 Grad Norm 0.075731 17.54s/it\n",
            "Train loss 157 0.044361 Grad Norm 0.129248 14.20s/it\n",
            "Train loss 158 0.018768 Grad Norm 0.045854 20.27s/it\n",
            "Train loss 159 0.013263 Grad Norm 0.032267 32.88s/it\n",
            "Train loss 160 0.057259 Grad Norm 0.206288 11.67s/it\n",
            "Train loss 161 0.014379 Grad Norm 0.042937 24.92s/it\n",
            "Train loss 162 0.022733 Grad Norm 0.057041 29.27s/it\n",
            "Epoch: 18\n",
            "Train loss 163 0.031726 Grad Norm 0.067864 9.12s/it\n",
            "Train loss 164 0.046403 Grad Norm 0.112197 20.20s/it\n",
            "Train loss 165 0.016358 Grad Norm 0.048170 20.33s/it\n",
            "Train loss 166 0.016639 Grad Norm 0.041939 24.89s/it\n",
            "Train loss 167 0.031612 Grad Norm 0.062681 33.10s/it\n",
            "Train loss 168 0.027962 Grad Norm 0.073483 13.05s/it\n",
            "Train loss 169 0.033657 Grad Norm 0.094697 13.81s/it\n",
            "Train loss 170 0.015094 Grad Norm 0.041536 29.20s/it\n",
            "Train loss 171 0.021145 Grad Norm 0.063423 24.94s/it\n",
            "Epoch: 19\n",
            "Train loss 172 0.017560 Grad Norm 0.054194 26.13s/it\n",
            "Train loss 173 0.016734 Grad Norm 0.041050 22.68s/it\n",
            "Train loss 174 0.019082 Grad Norm 0.045697 20.41s/it\n",
            "Train loss 175 0.017213 Grad Norm 0.037536 11.45s/it\n",
            "Train loss 176 0.021945 Grad Norm 0.067404 20.11s/it\n",
            "Train loss 177 0.021855 Grad Norm 0.070632 24.87s/it\n",
            "Train loss 178 0.021152 Grad Norm 0.085307 21.80s/it\n",
            "Train loss 179 0.016244 Grad Norm 0.048109 17.43s/it\n",
            "Train loss 180 0.013276 Grad Norm 0.037458 32.79s/it\n",
            "Validation loss 180:  0.031913\n",
            "Saving model and optimizer state at iteration 180 to best.pt\n",
            "Epoch: 20\n",
            "Train loss 181 0.053164 Grad Norm 0.145409 14.69s/it\n",
            "Train loss 182 0.011689 Grad Norm 0.027649 33.26s/it\n",
            "Train loss 183 0.023772 Grad Norm 0.073690 10.42s/it\n",
            "Train loss 184 0.027668 Grad Norm 0.078546 11.10s/it\n",
            "Train loss 185 0.013805 Grad Norm 0.034305 25.07s/it\n",
            "Train loss 186 0.032003 Grad Norm 0.110985 20.47s/it\n",
            "Train loss 187 0.013825 Grad Norm 0.059879 29.42s/it\n",
            "Train loss 188 0.017466 Grad Norm 0.042687 21.48s/it\n",
            "Train loss 189 0.015117 Grad Norm 0.030195 16.74s/it\n",
            "Epoch: 21\n",
            "Train loss 190 0.012360 Grad Norm 0.024987 33.85s/it\n",
            "Train loss 191 0.037001 Grad Norm 0.079091 20.34s/it\n",
            "Train loss 192 0.013701 Grad Norm 0.039237 20.37s/it\n",
            "Train loss 193 0.024213 Grad Norm 0.053730 10.86s/it\n",
            "Train loss 194 0.016820 Grad Norm 0.040784 12.77s/it\n",
            "Train loss 195 0.012852 Grad Norm 0.030674 25.25s/it\n",
            "Train loss 196 0.018901 Grad Norm 0.047230 13.75s/it\n",
            "Train loss 197 0.009963 Grad Norm 0.019843 24.79s/it\n",
            "Train loss 198 0.015771 Grad Norm 0.044182 22.48s/it\n",
            "Epoch: 22\n",
            "Train loss 199 0.021992 Grad Norm 0.066502 14.71s/it\n",
            "Train loss 200 0.010807 Grad Norm 0.031128 32.91s/it\n",
            "Train loss 201 0.018310 Grad Norm 0.041157 11.97s/it\n",
            "Train loss 202 0.017445 Grad Norm 0.035629 12.80s/it\n",
            "Train loss 203 0.011973 Grad Norm 0.034611 29.39s/it\n",
            "Train loss 204 0.011264 Grad Norm 0.029811 17.39s/it\n",
            "Train loss 205 0.011090 Grad Norm 0.025016 25.30s/it\n",
            "Train loss 206 0.012154 Grad Norm 0.038243 19.82s/it\n",
            "Train loss 207 0.007566 Grad Norm 0.015145 21.41s/it\n",
            "Epoch: 23\n",
            "Train loss 208 0.006757 Grad Norm 0.015540 30.60s/it\n",
            "Train loss 209 0.017293 Grad Norm 0.072404 20.51s/it\n",
            "Train loss 210 0.018802 Grad Norm 0.034609 8.32s/it\n",
            "Train loss 211 0.007197 Grad Norm 0.017406 22.90s/it\n",
            "Train loss 212 0.012145 Grad Norm 0.047125 25.05s/it\n",
            "Train loss 213 0.009655 Grad Norm 0.028704 21.92s/it\n",
            "Train loss 214 0.010227 Grad Norm 0.020966 20.27s/it\n",
            "Train loss 215 0.011041 Grad Norm 0.042440 32.81s/it\n",
            "Train loss 216 0.009541 Grad Norm 0.023708 17.43s/it\n",
            "Epoch: 24\n",
            "Train loss 217 0.011791 Grad Norm 0.030430 23.44s/it\n",
            "Train loss 218 0.013475 Grad Norm 0.038432 20.48s/it\n",
            "Train loss 219 0.005637 Grad Norm 0.013291 33.02s/it\n",
            "Train loss 220 0.007831 Grad Norm 0.015994 29.49s/it\n",
            "Train loss 221 0.006074 Grad Norm 0.011878 24.97s/it\n",
            "Train loss 222 0.007224 Grad Norm 0.017705 25.10s/it\n",
            "Train loss 223 0.010443 Grad Norm 0.037021 17.36s/it\n",
            "Train loss 224 0.010798 Grad Norm 0.021890 12.48s/it\n",
            "Train loss 225 0.006420 Grad Norm 0.021150 19.75s/it\n",
            "Validation loss 225:  0.014757\n",
            "Saving model and optimizer state at iteration 225 to best.pt\n",
            "Epoch: 25\n",
            "Train loss 226 0.008448 Grad Norm 0.020919 35.97s/it\n",
            "Train loss 227 0.013502 Grad Norm 0.032152 14.37s/it\n",
            "Train loss 228 0.008232 Grad Norm 0.024162 17.49s/it\n",
            "Train loss 229 0.011522 Grad Norm 0.025794 8.63s/it\n",
            "Train loss 230 0.006511 Grad Norm 0.018931 29.42s/it\n",
            "Train loss 231 0.008317 Grad Norm 0.019554 12.94s/it\n",
            "Train loss 232 0.008852 Grad Norm 0.023541 25.15s/it\n",
            "Train loss 233 0.009738 Grad Norm 0.024048 22.62s/it\n",
            "Train loss 234 0.006764 Grad Norm 0.025018 19.83s/it\n",
            "Epoch: 26\n",
            "Train loss 235 0.006735 Grad Norm 0.014159 20.97s/it\n",
            "Train loss 236 0.007903 Grad Norm 0.016377 21.88s/it\n",
            "Train loss 237 0.007156 Grad Norm 0.011983 25.32s/it\n",
            "Train loss 238 0.012323 Grad Norm 0.040314 20.53s/it\n",
            "Train loss 239 0.006834 Grad Norm 0.014507 33.01s/it\n",
            "Train loss 240 0.006070 Grad Norm 0.015190 25.26s/it\n",
            "Train loss 241 0.009390 Grad Norm 0.018464 8.72s/it\n",
            "Train loss 242 0.007644 Grad Norm 0.021096 12.44s/it\n",
            "Train loss 243 0.004995 Grad Norm 0.008703 29.14s/it\n",
            "Epoch: 27\n",
            "Train loss 244 0.007733 Grad Norm 0.024617 26.62s/it\n",
            "Train loss 245 0.005842 Grad Norm 0.009033 29.58s/it\n",
            "Train loss 246 0.009060 Grad Norm 0.019448 10.46s/it\n",
            "Train loss 247 0.010282 Grad Norm 0.033224 14.15s/it\n",
            "Train loss 248 0.007618 Grad Norm 0.018486 32.88s/it\n",
            "Train loss 249 0.008618 Grad Norm 0.021685 20.41s/it\n",
            "Train loss 250 0.010577 Grad Norm 0.028744 11.21s/it\n",
            "Train loss 251 0.006661 Grad Norm 0.009535 22.49s/it\n",
            "Train loss 252 0.007111 Grad Norm 0.014876 20.04s/it\n",
            "Epoch: 28\n",
            "Train loss 253 0.006188 Grad Norm 0.024427 33.77s/it\n",
            "Train loss 254 0.006163 Grad Norm 0.015059 21.69s/it\n",
            "Train loss 255 0.006184 Grad Norm 0.009884 17.87s/it\n",
            "Train loss 256 0.013204 Grad Norm 0.030352 11.71s/it\n",
            "Train loss 257 0.011366 Grad Norm 0.021691 17.06s/it\n",
            "Train loss 258 0.005262 Grad Norm 0.009786 24.87s/it\n",
            "Train loss 259 0.006881 Grad Norm 0.015799 29.41s/it\n",
            "Train loss 260 0.010706 Grad Norm 0.034905 9.66s/it\n",
            "Train loss 261 0.006113 Grad Norm 0.010699 22.48s/it\n",
            "Epoch: 29\n",
            "Train loss 262 0.005463 Grad Norm 0.016686 30.14s/it\n",
            "Train loss 263 0.006362 Grad Norm 0.022916 25.42s/it\n",
            "Train loss 264 0.007202 Grad Norm 0.020880 24.99s/it\n",
            "Train loss 265 0.006264 Grad Norm 0.013158 21.68s/it\n",
            "Train loss 266 0.005991 Grad Norm 0.010238 17.58s/it\n",
            "Train loss 267 0.008991 Grad Norm 0.011373 16.95s/it\n",
            "Train loss 268 0.013985 Grad Norm 0.022741 8.21s/it\n",
            "Train loss 269 0.006704 Grad Norm 0.016526 19.76s/it\n",
            "Train loss 270 0.005509 Grad Norm 0.012280 32.74s/it\n",
            "Validation loss 270:  0.011275\n",
            "Saving model and optimizer state at iteration 270 to best.pt\n",
            "Epoch: 30\n",
            "Train loss 271 0.012935 Grad Norm 0.024960 7.65s/it\n",
            "Train loss 272 0.005651 Grad Norm 0.008524 21.61s/it\n",
            "Train loss 273 0.005305 Grad Norm 0.008648 25.03s/it\n",
            "Train loss 274 0.005431 Grad Norm 0.011210 33.00s/it\n",
            "Train loss 275 0.004981 Grad Norm 0.009493 25.17s/it\n",
            "Train loss 276 0.015500 Grad Norm 0.049439 14.31s/it\n",
            "Train loss 277 0.006045 Grad Norm 0.007537 22.74s/it\n",
            "Train loss 278 0.005402 Grad Norm 0.013185 17.39s/it\n",
            "Train loss 279 0.007506 Grad Norm 0.035257 19.84s/it\n",
            "Epoch: 31\n",
            "Train loss 280 0.005281 Grad Norm 0.015329 33.95s/it\n",
            "Train loss 281 0.007467 Grad Norm 0.030479 25.36s/it\n",
            "Train loss 282 0.007114 Grad Norm 0.015080 20.12s/it\n",
            "Train loss 283 0.006979 Grad Norm 0.014623 21.52s/it\n",
            "Train loss 284 0.007131 Grad Norm 0.013444 17.57s/it\n",
            "Train loss 285 0.006415 Grad Norm 0.016085 11.10s/it\n",
            "Train loss 286 0.008955 Grad Norm 0.016615 12.77s/it\n",
            "Train loss 287 0.020322 Grad Norm 0.071157 7.74s/it\n",
            "Train loss 288 0.004523 Grad Norm 0.006658 29.16s/it\n",
            "Epoch: 32\n",
            "Train loss 289 0.007792 Grad Norm 0.028802 21.19s/it\n",
            "Train loss 290 0.012597 Grad Norm 0.058225 13.94s/it\n",
            "Train loss 291 0.009616 Grad Norm 0.017228 8.02s/it\n",
            "Train loss 292 0.003582 Grad Norm 0.008430 24.91s/it\n",
            "Train loss 293 0.006910 Grad Norm 0.014100 22.70s/it\n",
            "Train loss 294 0.014246 Grad Norm 0.045670 11.12s/it\n",
            "Train loss 295 0.012167 Grad Norm 0.051306 17.79s/it\n",
            "Train loss 296 0.006440 Grad Norm 0.017303 32.75s/it\n",
            "Train loss 297 0.006752 Grad Norm 0.021893 24.86s/it\n",
            "Epoch: 33\n",
            "Train loss 298 0.005890 Grad Norm 0.025625 33.73s/it\n",
            "Train loss 299 0.013301 Grad Norm 0.041336 10.38s/it\n",
            "Train loss 300 0.010535 Grad Norm 0.032448 14.20s/it\n",
            "Train loss 301 0.005724 Grad Norm 0.013032 17.76s/it\n",
            "Train loss 302 0.005678 Grad Norm 0.014055 25.36s/it\n",
            "Train loss 303 0.013813 Grad Norm 0.041007 8.78s/it\n",
            "Train loss 304 0.006850 Grad Norm 0.018350 29.41s/it\n",
            "Train loss 305 0.006790 Grad Norm 0.018945 20.04s/it\n",
            "Train loss 306 0.009074 Grad Norm 0.025409 16.72s/it\n",
            "Epoch: 34\n",
            "Train loss 307 0.010128 Grad Norm 0.024081 13.48s/it\n",
            "Train loss 308 0.005917 Grad Norm 0.026669 32.97s/it\n",
            "Train loss 309 0.012342 Grad Norm 0.022215 6.98s/it\n",
            "Train loss 310 0.005744 Grad Norm 0.012573 25.14s/it\n",
            "Train loss 311 0.006493 Grad Norm 0.020995 20.12s/it\n",
            "Train loss 312 0.008235 Grad Norm 0.011708 13.77s/it\n",
            "Train loss 313 0.005502 Grad Norm 0.014198 20.32s/it\n",
            "Train loss 314 0.006418 Grad Norm 0.014059 24.79s/it\n",
            "Train loss 315 0.005014 Grad Norm 0.010450 29.22s/it\n",
            "Validation loss 315:  0.011264\n",
            "Saving model and optimizer state at iteration 315 to best.pt\n",
            "Epoch: 35\n",
            "Train loss 316 0.007469 Grad Norm 0.017980 22.01s/it\n",
            "Train loss 317 0.009290 Grad Norm 0.012406 8.47s/it\n",
            "Train loss 318 0.004805 Grad Norm 0.006701 22.95s/it\n",
            "Train loss 319 0.007530 Grad Norm 0.020330 11.61s/it\n",
            "Train loss 320 0.008827 Grad Norm 0.022396 20.48s/it\n",
            "Train loss 321 0.005590 Grad Norm 0.013118 33.02s/it\n",
            "Train loss 322 0.005267 Grad Norm 0.013218 25.12s/it\n",
            "Train loss 323 0.004668 Grad Norm 0.007260 29.26s/it\n",
            "Train loss 324 0.010419 Grad Norm 0.016528 11.45s/it\n",
            "Epoch: 36\n",
            "Train loss 325 0.006553 Grad Norm 0.016203 20.78s/it\n",
            "Train loss 326 0.006899 Grad Norm 0.015480 21.75s/it\n",
            "Train loss 327 0.003853 Grad Norm 0.008797 29.36s/it\n",
            "Train loss 328 0.005964 Grad Norm 0.012495 25.05s/it\n",
            "Train loss 329 0.009293 Grad Norm 0.016924 12.89s/it\n",
            "Train loss 330 0.005662 Grad Norm 0.009756 22.69s/it\n",
            "Train loss 331 0.004993 Grad Norm 0.009149 32.91s/it\n",
            "Train loss 332 0.005495 Grad Norm 0.008634 19.97s/it\n",
            "Train loss 333 0.007433 Grad Norm 0.014934 10.80s/it\n",
            "Epoch: 37\n",
            "Train loss 334 0.006461 Grad Norm 0.010719 23.28s/it\n",
            "Train loss 335 0.004984 Grad Norm 0.005715 25.02s/it\n",
            "Train loss 336 0.004575 Grad Norm 0.006016 29.37s/it\n",
            "Train loss 337 0.008209 Grad Norm 0.013548 12.90s/it\n",
            "Train loss 338 0.005254 Grad Norm 0.011079 32.79s/it\n",
            "Train loss 339 0.005035 Grad Norm 0.008356 20.43s/it\n",
            "Train loss 340 0.009852 Grad Norm 0.019161 10.71s/it\n",
            "Train loss 341 0.002903 Grad Norm 0.005144 24.80s/it\n",
            "Train loss 342 0.008308 Grad Norm 0.012934 19.86s/it\n",
            "Epoch: 38\n",
            "Train loss 343 0.006705 Grad Norm 0.009371 14.38s/it\n",
            "Train loss 344 0.004183 Grad Norm 0.007693 21.72s/it\n",
            "Train loss 345 0.005569 Grad Norm 0.006598 25.00s/it\n",
            "Train loss 346 0.005592 Grad Norm 0.007675 17.73s/it\n",
            "Train loss 347 0.011608 Grad Norm 0.018788 8.42s/it\n",
            "Train loss 348 0.005654 Grad Norm 0.006269 22.81s/it\n",
            "Train loss 349 0.005612 Grad Norm 0.009402 29.51s/it\n",
            "Train loss 350 0.003739 Grad Norm 0.004277 32.74s/it\n",
            "Train loss 351 0.008240 Grad Norm 0.021072 20.11s/it\n",
            "Epoch: 39\n",
            "Train loss 352 0.007765 Grad Norm 0.014990 17.81s/it\n",
            "Train loss 353 0.006326 Grad Norm 0.008133 20.32s/it\n",
            "Train loss 354 0.004295 Grad Norm 0.004292 29.60s/it\n",
            "Train loss 355 0.010859 Grad Norm 0.012495 11.87s/it\n",
            "Train loss 356 0.004429 Grad Norm 0.006513 32.76s/it\n",
            "Train loss 357 0.004607 Grad Norm 0.004662 24.97s/it\n",
            "Train loss 358 0.008860 Grad Norm 0.013582 10.24s/it\n",
            "Train loss 359 0.009276 Grad Norm 0.011832 8.01s/it\n",
            "Train loss 360 0.005778 Grad Norm 0.005685 22.48s/it\n",
            "Validation loss 360:  0.009318\n",
            "Saving model and optimizer state at iteration 360 to best.pt\n",
            "Epoch: 40\n",
            "Train loss 361 0.005520 Grad Norm 0.009815 26.27s/it\n",
            "Train loss 362 0.011451 Grad Norm 0.009573 8.81s/it\n",
            "Train loss 363 0.007963 Grad Norm 0.007981 11.38s/it\n",
            "Train loss 364 0.004330 Grad Norm 0.004563 24.96s/it\n",
            "Train loss 365 0.006671 Grad Norm 0.014537 14.13s/it\n",
            "Train loss 366 0.003684 Grad Norm 0.003578 21.49s/it\n",
            "Train loss 367 0.003740 Grad Norm 0.003612 32.88s/it\n",
            "Train loss 368 0.006438 Grad Norm 0.006614 20.07s/it\n",
            "Train loss 369 0.007278 Grad Norm 0.008065 17.43s/it\n",
            "Epoch: 41\n",
            "Train loss 370 0.004459 Grad Norm 0.004626 17.95s/it\n",
            "Train loss 371 0.004910 Grad Norm 0.004695 20.28s/it\n",
            "Train loss 372 0.005682 Grad Norm 0.005927 32.92s/it\n",
            "Train loss 373 0.007041 Grad Norm 0.007920 12.89s/it\n",
            "Train loss 374 0.002980 Grad Norm 0.003583 25.01s/it\n",
            "Train loss 375 0.004577 Grad Norm 0.003973 29.28s/it\n",
            "Train loss 376 0.007084 Grad Norm 0.013740 20.12s/it\n",
            "Train loss 377 0.005038 Grad Norm 0.003822 21.42s/it\n",
            "Train loss 378 0.009449 Grad Norm 0.008594 11.43s/it\n",
            "Epoch: 42\n",
            "Train loss 379 0.006535 Grad Norm 0.004871 25.82s/it\n",
            "Train loss 380 0.006753 Grad Norm 0.005451 11.54s/it\n",
            "Train loss 381 0.004368 Grad Norm 0.002851 21.73s/it\n",
            "Train loss 382 0.003421 Grad Norm 0.002926 32.87s/it\n",
            "Train loss 383 0.005579 Grad Norm 0.004634 25.10s/it\n",
            "Train loss 384 0.006718 Grad Norm 0.006387 13.77s/it\n",
            "Train loss 385 0.004285 Grad Norm 0.003455 29.24s/it\n",
            "Train loss 386 0.004958 Grad Norm 0.005016 19.86s/it\n",
            "Train loss 387 0.010256 Grad Norm 0.009830 8.33s/it\n",
            "Epoch: 43\n",
            "Train loss 388 0.007044 Grad Norm 0.005164 13.95s/it\n",
            "Train loss 389 0.005065 Grad Norm 0.005026 10.27s/it\n",
            "Train loss 390 0.007439 Grad Norm 0.005407 12.62s/it\n",
            "Train loss 391 0.006634 Grad Norm 0.004652 20.35s/it\n",
            "Train loss 392 0.006885 Grad Norm 0.007094 8.31s/it\n",
            "Train loss 393 0.005628 Grad Norm 0.005441 25.05s/it\n",
            "Train loss 394 0.005446 Grad Norm 0.003805 29.42s/it\n",
            "Train loss 395 0.006691 Grad Norm 0.004196 16.74s/it\n",
            "Train loss 396 0.004812 Grad Norm 0.002948 24.81s/it\n",
            "Epoch: 44\n",
            "Train loss 397 0.005832 Grad Norm 0.004185 18.14s/it\n",
            "Train loss 398 0.007894 Grad Norm 0.006141 13.57s/it\n",
            "Train loss 399 0.005660 Grad Norm 0.004532 25.04s/it\n",
            "Train loss 400 0.003771 Grad Norm 0.002133 29.27s/it\n",
            "Train loss 401 0.004721 Grad Norm 0.002707 21.66s/it\n",
            "Train loss 402 0.003038 Grad Norm 0.002260 32.76s/it\n",
            "Train loss 403 0.006485 Grad Norm 0.005491 22.74s/it\n",
            "Train loss 404 0.012080 Grad Norm 0.010387 8.04s/it\n",
            "Train loss 405 0.004137 Grad Norm 0.002761 24.73s/it\n",
            "Validation loss 405:  0.008983\n",
            "Saving model and optimizer state at iteration 405 to best.pt\n",
            "Epoch: 45\n",
            "Train loss 406 0.008349 Grad Norm 0.005618 9.13s/it\n",
            "Train loss 407 0.007329 Grad Norm 0.005259 21.91s/it\n",
            "Train loss 408 0.010976 Grad Norm 0.007190 7.20s/it\n",
            "Train loss 409 0.005979 Grad Norm 0.003574 24.86s/it\n",
            "Train loss 410 0.006039 Grad Norm 0.004442 20.02s/it\n",
            "Train loss 411 0.003462 Grad Norm 0.002538 20.29s/it\n",
            "Train loss 412 0.003661 Grad Norm 0.002856 24.94s/it\n",
            "Train loss 413 0.004713 Grad Norm 0.002823 29.18s/it\n",
            "Train loss 414 0.005636 Grad Norm 0.003259 16.75s/it\n",
            "Epoch: 46\n",
            "Train loss 415 0.004665 Grad Norm 0.002517 29.79s/it\n",
            "Train loss 416 0.004941 Grad Norm 0.003000 20.30s/it\n",
            "Train loss 417 0.004727 Grad Norm 0.002697 20.02s/it\n",
            "Train loss 418 0.008562 Grad Norm 0.005853 11.59s/it\n",
            "Train loss 419 0.008722 Grad Norm 0.006163 8.34s/it\n",
            "Train loss 420 0.006156 Grad Norm 0.004533 25.05s/it\n",
            "Train loss 421 0.005888 Grad Norm 0.003362 22.72s/it\n",
            "Train loss 422 0.004897 Grad Norm 0.003259 32.77s/it\n",
            "Train loss 423 0.005397 Grad Norm 0.003053 17.47s/it\n",
            "Epoch: 47\n",
            "Train loss 424 0.006185 Grad Norm 0.003680 20.99s/it\n",
            "Train loss 425 0.006222 Grad Norm 0.003771 17.26s/it\n",
            "Train loss 426 0.003872 Grad Norm 0.002284 22.51s/it\n",
            "Train loss 427 0.006364 Grad Norm 0.004038 17.55s/it\n",
            "Train loss 428 0.004883 Grad Norm 0.002897 21.51s/it\n",
            "Train loss 429 0.009446 Grad Norm 0.006830 11.34s/it\n",
            "Train loss 430 0.008498 Grad Norm 0.006824 8.34s/it\n",
            "Train loss 431 0.004374 Grad Norm 0.002889 32.78s/it\n",
            "Train loss 432 0.003809 Grad Norm 0.002094 29.20s/it\n",
            "Epoch: 48\n",
            "Train loss 433 0.003993 Grad Norm 0.002814 33.42s/it\n",
            "Train loss 434 0.007946 Grad Norm 0.004881 10.67s/it\n",
            "Train loss 435 0.008792 Grad Norm 0.005439 8.41s/it\n",
            "Train loss 436 0.002863 Grad Norm 0.002296 25.09s/it\n",
            "Train loss 437 0.010372 Grad Norm 0.005777 16.98s/it\n",
            "Train loss 438 0.006079 Grad Norm 0.003635 20.11s/it\n",
            "Train loss 439 0.003481 Grad Norm 0.002149 29.24s/it\n",
            "Train loss 440 0.006729 Grad Norm 0.003587 24.83s/it\n",
            "Train loss 441 0.004282 Grad Norm 0.002796 21.41s/it\n",
            "Epoch: 49\n",
            "Train loss 442 0.007318 Grad Norm 0.004603 13.99s/it\n",
            "Train loss 443 0.006498 Grad Norm 0.003172 24.99s/it\n",
            "Train loss 444 0.005917 Grad Norm 0.004371 17.22s/it\n",
            "Train loss 445 0.006256 Grad Norm 0.004623 17.62s/it\n",
            "Train loss 446 0.004972 Grad Norm 0.002726 20.00s/it\n",
            "Train loss 447 0.004828 Grad Norm 0.002805 33.01s/it\n",
            "Train loss 448 0.005884 Grad Norm 0.003124 16.90s/it\n",
            "Train loss 449 0.005726 Grad Norm 0.004086 20.06s/it\n",
            "Train loss 450 0.009036 Grad Norm 0.006940 9.64s/it\n",
            "Validation loss 450:  0.008943\n",
            "Saving model and optimizer state at iteration 450 to best.pt\n"
          ]
        }
      ]
    }
  ]
}